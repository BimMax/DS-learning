{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение возраста покупателей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Описание проекта:**\n",
    "\n",
    "Сетевой супермаркет внедряет систему компьютерного зрения для обработки фотографий покупателей. \n",
    "Фотофиксация в прикассовой зоне поможет определять возраст клиентов, чтобы:\n",
    "* Анализировать покупки и предлагать товары, которые могут заинтересовать покупателей этой возрастной группы;\n",
    "* Контролировать добросовестность кассиров при продаже алкоголя.\n",
    "\n",
    "**Цель проекта:**\n",
    "\n",
    "Модель, которая по фотографии определит приблизительный возраст человека.\n",
    "\n",
    "**Критерии качества:**\n",
    "\n",
    "Метрика МАЕ меньше 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследовательский анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, AvgPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/datasets/faces/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение возрастов в выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(font_scale = 1.5)\n",
    "plt.figure(figsize = (30,10))\n",
    "sns.countplot(labels['real_age'])\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что людей сстарше 60 лет гораздо меньше чем более молодых. Людей в возрасте от 14-40 лет больше всего - больше 100 человек для каждого возраста в этом диапазоне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "datagen_flow = datagen.flow_from_directory(\n",
    "    '/datasets/faces/',\n",
    "\n",
    "    target_size=(150, 150),\n",
    "    batch_size=16,\n",
    "    class_mode='sparse',\n",
    "    subset='training',\n",
    "    seed=12345)\n",
    "\n",
    "\n",
    "features, target = next(datagen_flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выводим 16 изображений\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(16):\n",
    "    indexes = datagen_flow.index_array[:16]\n",
    "    fig.add_subplot(4, 4, i+1).set_title(f'Возраст: {labels.real_age.iloc[indexes[i]]}')\n",
    "    plt.imshow(features[i])\n",
    "\t# для компактности удаляем оси и прижимаем изображения друг к другу\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #plt\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод по результатам исследования:\n",
    "\n",
    "Судя по распределению возраста в имеющихся данных лучше всего должны будут быть распознаны лица людей в возрасте от 20 до 41 года, так же достаточно много данных для детей возрастом до 5 лет, а вот с рапознаванием возраста людей страше 70 лет достаточно мало данных и могут быть трудности. Так же есть фото, например, с жевательной резинкой, которая закрывает часть лица - такие фото ухудшат обучаемость. Есть фото повернутые, есть черно-белые."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train(path):\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        horizontal_flip=True,\n",
    "        rescale=1./255)\n",
    "    train_gen_flow = train_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='training',\n",
    "        seed=12345)\n",
    "    return train_gen_flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test(path):\n",
    "    labels = pd.read_csv(path + 'labels.csv')\n",
    "    test_datagen = ImageDataGenerator(\n",
    "        validation_split=0.25,\n",
    "        rescale=1./255)\n",
    "    test_gen_flow = test_datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=path + 'final_files/',\n",
    "        x_col='file_name',\n",
    "        y_col='real_age',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=16,\n",
    "        class_mode='raw',\n",
    "        subset='validation',\n",
    "        seed=12345)\n",
    "    return test_gen_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape):\n",
    "    backbone = ResNet50(weights='imagenet', \n",
    "                        input_shape=input_shape,\n",
    "                        include_top=False)\n",
    "    model = Sequential()\n",
    "    model.add(backbone)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    optimizer = Adam(lr=0.0005)\n",
    "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_data, test_data, batch_size=None, epochs=20,\n",
    "                steps_per_epoch=None, validation_steps=None):\n",
    "    if steps_per_epoch is None:\n",
    "        steps_per_epoch = len(train_data)\n",
    "    if validation_steps is None:\n",
    "        validation_steps = len(test_data)\n",
    "    model.fit(train_data, \n",
    "              validation_data=test_data,\n",
    "              batch_size=batch_size, epochs=epochs,\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              validation_steps=validation_steps,\n",
    "              verbose=2)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисление производилось на сторонних мощностях. Ниже приведен результат вычисления. Поставленная цель достигнута."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат обучения:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Train for 356 steps, validate for 119 steps\n",
    "Epoch 1/20\n",
    "2021-07-29 13:59:50.556586: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
    "2021-07-29 13:59:50.842363: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
    "356/356 - 46s - loss: 209.9321 - mae: 10.9374 - val_loss: 629.9441 - val_mae: 20.1435\n",
    "Epoch 2/20\n",
    "356/356 - 37s - loss: 135.2814 - mae: 8.8849 - val_loss: 225.1827 - val_mae: 11.8003\n",
    "Epoch 3/20\n",
    "356/356 - 37s - loss: 111.6643 - mae: 8.0298 - val_loss: 130.5670 - val_mae: 9.0427\n",
    "Epoch 4/20\n",
    "356/356 - 38s - loss: 91.3143 - mae: 7.3465 - val_loss: 120.7078 - val_mae: 8.2999\n",
    "Epoch 5/20\n",
    "356/356 - 38s - loss: 81.2874 - mae: 6.8389 - val_loss: 157.4068 - val_mae: 9.2262\n",
    "Epoch 6/20\n",
    "356/356 - 38s - loss: 71.0115 - mae: 6.4768 - val_loss: 127.3828 - val_mae: 8.5481\n",
    "Epoch 7/20\n",
    "356/356 - 38s - loss: 54.9083 - mae: 5.7000 - val_loss: 128.8676 - val_mae: 8.6193\n",
    "Epoch 8/20\n",
    "356/356 - 38s - loss: 47.8948 - mae: 5.3213 - val_loss: 93.2415 - val_mae: 7.2711\n",
    "Epoch 9/20\n",
    "356/356 - 38s - loss: 39.8999 - mae: 4.8333 - val_loss: 96.5398 - val_mae: 7.4227\n",
    "Epoch 10/20\n",
    "356/356 - 38s - loss: 34.2201 - mae: 4.5080 - val_loss: 99.8048 - val_mae: 7.3277\n",
    "Epoch 11/20\n",
    "356/356 - 38s - loss: 31.1639 - mae: 4.2972 - val_loss: 102.3363 - val_mae: 7.6928\n",
    "Epoch 12/20\n",
    "356/356 - 38s - loss: 27.1053 - mae: 4.0281 - val_loss: 98.4520 - val_mae: 7.5206\n",
    "Epoch 13/20\n",
    "356/356 - 38s - loss: 24.7616 - mae: 3.8111 - val_loss: 94.8010 - val_mae: 7.4353\n",
    "Epoch 14/20\n",
    "356/356 - 38s - loss: 25.8449 - mae: 3.9135 - val_loss: 93.6739 - val_mae: 7.3047\n",
    "Epoch 15/20\n",
    "356/356 - 38s - loss: 24.9931 - mae: 3.8217 - val_loss: 87.3194 - val_mae: 7.0132\n",
    "Epoch 16/20\n",
    "356/356 - 38s - loss: 19.8076 - mae: 3.4278 - val_loss: 78.0335 - val_mae: 6.6319\n",
    "Epoch 17/20\n",
    "356/356 - 38s - loss: 18.6851 - mae: 3.3224 - val_loss: 91.9763 - val_mae: 7.1595\n",
    "Epoch 18/20\n",
    "356/356 - 38s - loss: 17.8242 - mae: 3.2381 - val_loss: 82.7343 - val_mae: 6.8413\n",
    "Epoch 19/20\n",
    "356/356 - 38s - loss: 15.6390 - mae: 3.0600 - val_loss: 92.9889 - val_mae: 7.4051\n",
    "Epoch 20/20\n",
    "356/356 - 38s - loss: 15.6837 - mae: 3.0655 - val_loss: 82.1044 - val_mae: 7.0108\n",
    "WARNING:tensorflow:sample_weight modes were coerced from\n",
    "  ...\n",
    "    to  \n",
    "  ['...']\n",
    "119/119 - 9s - loss: 82.1044 - mae: 7.0108\n",
    "Test MAE: 7.0108\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 4994,
    "start_time": "2021-07-27T17:12:38.876Z"
   },
   {
    "duration": 29,
    "start_time": "2021-07-27T17:12:43.873Z"
   },
   {
    "duration": 7,
    "start_time": "2021-07-27T17:12:43.905Z"
   },
   {
    "duration": 15,
    "start_time": "2021-07-27T17:12:43.915Z"
   },
   {
    "duration": 2275,
    "start_time": "2021-07-27T17:12:43.932Z"
   },
   {
    "duration": 17,
    "start_time": "2021-07-27T17:12:46.209Z"
   },
   {
    "duration": 931,
    "start_time": "2021-07-27T17:12:46.228Z"
   },
   {
    "duration": 2131,
    "start_time": "2021-07-27T17:12:47.161Z"
   },
   {
    "duration": 130,
    "start_time": "2021-07-27T17:12:49.294Z"
   },
   {
    "duration": 5,
    "start_time": "2021-07-27T17:15:27.217Z"
   },
   {
    "duration": 801,
    "start_time": "2021-07-27T17:15:34.764Z"
   },
   {
    "duration": 113,
    "start_time": "2021-07-27T17:18:07.994Z"
   },
   {
    "duration": 328,
    "start_time": "2021-07-27T17:18:14.884Z"
   },
   {
    "duration": 350,
    "start_time": "2021-07-27T17:18:31.946Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T17:18:38.777Z"
   },
   {
    "duration": 431,
    "start_time": "2021-07-27T17:19:25.004Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-27T17:19:33.773Z"
   },
   {
    "duration": 14767,
    "start_time": "2021-07-29T15:38:42.878Z"
   },
   {
    "duration": -324,
    "start_time": "2021-07-29T15:38:57.971Z"
   },
   {
    "duration": -323,
    "start_time": "2021-07-29T15:38:57.972Z"
   },
   {
    "duration": -324,
    "start_time": "2021-07-29T15:38:57.974Z"
   },
   {
    "duration": -324,
    "start_time": "2021-07-29T15:38:57.975Z"
   },
   {
    "duration": -327,
    "start_time": "2021-07-29T15:38:57.980Z"
   },
   {
    "duration": -327,
    "start_time": "2021-07-29T15:38:57.981Z"
   },
   {
    "duration": -326,
    "start_time": "2021-07-29T15:38:57.982Z"
   },
   {
    "duration": -326,
    "start_time": "2021-07-29T15:38:57.983Z"
   },
   {
    "duration": 13,
    "start_time": "2021-07-29T15:39:01.517Z"
   },
   {
    "duration": 45,
    "start_time": "2021-07-29T15:39:01.532Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-29T15:39:01.581Z"
   },
   {
    "duration": 32,
    "start_time": "2021-07-29T15:39:01.591Z"
   },
   {
    "duration": 2178,
    "start_time": "2021-07-29T15:39:01.626Z"
   },
   {
    "duration": 19,
    "start_time": "2021-07-29T15:39:03.806Z"
   },
   {
    "duration": 1547,
    "start_time": "2021-07-29T15:39:03.827Z"
   },
   {
    "duration": 2355,
    "start_time": "2021-07-29T15:39:05.376Z"
   },
   {
    "duration": 4,
    "start_time": "2021-07-29T15:39:07.734Z"
   },
   {
    "duration": 7613,
    "start_time": "2021-07-29T16:18:19.727Z"
   },
   {
    "duration": 43,
    "start_time": "2021-07-29T16:18:27.343Z"
   },
   {
    "duration": 8,
    "start_time": "2021-07-29T16:19:54.971Z"
   },
   {
    "duration": 16,
    "start_time": "2021-07-29T16:19:55.965Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-24T13:00:20.996Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-24T13:00:33.058Z"
   },
   {
    "duration": 4,
    "start_time": "2021-08-24T13:00:40.380Z"
   },
   {
    "duration": 9,
    "start_time": "2021-08-24T13:00:43.600Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
